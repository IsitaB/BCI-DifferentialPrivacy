{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "zkN8zr815hQN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zkN8zr815hQN",
        "outputId": "68239627-0f66-40d0-fcf1-447562ab9625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n",
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.14.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.14.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.72.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n",
            "Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: wrapt, tensorflow-estimator, protobuf, ml-dtypes, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 ml-dtypes-0.2.0 protobuf-4.25.8 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "82ce5ab2ca104ba89bfe7f124b6d60bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_privacy==0.9.0\n",
            "  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_privacy==0.9.0) (1.4.0)\n",
            "Collecting dm-tree==0.1.8 (from tensorflow_privacy==0.9.0)\n",
            "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting dp-accounting==0.4.3 (from tensorflow_privacy==0.9.0)\n",
            "  Downloading dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting numpy~=1.21 (from tensorflow_privacy==0.9.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging~=22.0 (from tensorflow_privacy==0.9.0)\n",
            "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_privacy==0.9.0) (1.6.1)\n",
            "Requirement already satisfied: scipy~=1.9 in /usr/local/lib/python3.11/dist-packages (from tensorflow_privacy==0.9.0) (1.15.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow_privacy==0.9.0) (2.14.0)\n",
            "Collecting tensorflow-probability~=0.22.0 (from tensorflow_privacy==0.9.0)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow_privacy==0.9.0) (2.14.0)\n",
            "Requirement already satisfied: attrs>=22 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.3->tensorflow_privacy==0.9.0) (25.3.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.3->tensorflow_privacy==0.9.0) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow_privacy==0.9.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow_privacy==0.9.0) (3.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (4.14.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (2.14.1)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow_privacy==0.9.0) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.22.0->tensorflow_privacy==0.9.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.22.0->tensorflow_privacy==0.9.0) (3.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow_privacy==0.9.0) (3.2.2)\n",
            "Downloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dm-tree, packaging, numpy, tensorflow-probability, dp-accounting, tensorflow_privacy\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.9\n",
            "    Uninstalling dm-tree-0.1.9:\n",
            "      Successfully uninstalled dm-tree-0.1.9\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.3.44 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 22.0 which is incompatible.\n",
            "xarray 2025.3.1 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "sphinx 8.2.3 requires packaging>=23.0, but you have packaging 22.0 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "google-cloud-bigquery 3.34.0 requires packaging>=24.2.0, but you have packaging 22.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "langchain-core 0.3.63 requires packaging<25,>=23.2, but you have packaging 22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dm-tree-0.1.8 dp-accounting-0.4.3 numpy-1.26.4 packaging-22.0 tensorflow-probability-0.22.1 tensorflow_privacy-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "bd45ed2932db4596b7722deaf57fb210"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install mne\n",
        "!pip install tensorflow==2.14.0\n",
        "!pip install tensorflow_privacy==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fp3ecrJr5yYt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp3ecrJr5yYt",
        "outputId": "bcd4224b-d07b-4ec4-fb84-7e39fc9f79ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy==1.26.4\n",
        "!pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZkddtaPm6s__",
      "metadata": {
        "id": "ZkddtaPm6s__"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb1f9f9-8ef4-4367-8839-0b0498fbf29d",
      "metadata": {
        "id": "afb1f9f9-8ef4-4367-8839-0b0498fbf29d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# mne imports\n",
        "import mne\n",
        "from mne import io\n",
        "from mne.datasets import sample\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from EEGModels import EEGNet\n",
        "from EEGModels import DeepConvNet\n",
        "from EEGModels import ShallowConvNet\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# PyRiemann imports\n",
        "# from pyriemann.estimation import XdawnCovariances\n",
        "# from pyriemann.tangentspace import TangentSpace\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a7d25d-6235-4344-9397-5f62f72c1c87",
      "metadata": {
        "id": "a1a7d25d-6235-4344-9397-5f62f72c1c87"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy_lib\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe2cbd6-20ea-4a87-9bd9-88d2380189be",
      "metadata": {
        "id": "0fe2cbd6-20ea-4a87-9bd9-88d2380189be"
      },
      "outputs": [],
      "source": [
        "# while the default tensorflow ordering is 'channels_last' we set it here\n",
        "# to be explicit in case if the user has changed the default ordering\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "##################### Process, filter and epoch the data ######################\n",
        "data_path = str(sample.data_path())\n",
        "\n",
        "# Set parameters and read data\n",
        "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
        "event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
        "tmin, tmax = -0., 1\n",
        "event_id = dict(aud_l=1, aud_r=2, vis_l=3, vis_r=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed7be3a-7726-4c88-8328-4b984fbc6d0f",
      "metadata": {
        "id": "fed7be3a-7726-4c88-8328-4b984fbc6d0f"
      },
      "outputs": [],
      "source": [
        "# Setup for reading the raw data\n",
        "raw = io.Raw(raw_fname, preload=True, verbose=False)\n",
        "raw.filter(2, None, method='iir')  # replace baselining with high-pass\n",
        "events = mne.read_events(event_fname)\n",
        "\n",
        "raw.info['bads'] = ['MEG 2443']  # set bad channels\n",
        "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
        "                       exclude='bads')\n",
        "\n",
        "# Read epochs\n",
        "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=False,\n",
        "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
        "labels = epochs.events[:, -1]\n",
        "\n",
        "# extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
        "X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
        "y = labels\n",
        "\n",
        "kernels, chans, samples = 1, 60, 151"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7gvR6wJf5N5C",
      "metadata": {
        "id": "7gvR6wJf5N5C"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3b0f3f-a29a-4ad2-93e0-eee3e69f381e",
      "metadata": {
        "id": "6a3b0f3f-a29a-4ad2-93e0-eee3e69f381e"
      },
      "outputs": [],
      "source": [
        "# take 50/25/25 percent of the data to train/validate/test\n",
        "X_train      = X[0:144,]\n",
        "Y_train      = y[0:144]\n",
        "X_validate   = X[144:208,]\n",
        "Y_validate   = y[144:208]\n",
        "X_test       = X[208:,]\n",
        "Y_test       = y[208:]\n",
        "\n",
        "############################# EEGNet portion ##################################\n",
        "\n",
        "# convert labels to one-hot encodings.\n",
        "Y_train      = np_utils.to_categorical(Y_train-1)\n",
        "Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
        "Y_test       = np_utils.to_categorical(Y_test-1)\n",
        "\n",
        "# convert data to NHWC (trials, channels, samples, kernels) format. Data\n",
        "# contains 60 channels and 151 time-points. Set the number of kernels to 1.\n",
        "X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
        "X_validate   = X_validate.reshape(X_validate.shape[0], chans, samples, kernels)\n",
        "X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2x5M4Ue5bzP",
      "metadata": {
        "id": "a2x5M4Ue5bzP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('./tmp', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef895be-5551-477b-aaba-7ba83244c5e5",
      "metadata": {
        "id": "9ef895be-5551-477b-aaba-7ba83244c5e5"
      },
      "outputs": [],
      "source": [
        "model = ShallowConvNet(nb_classes = 4, Chans = chans, Samples = samples, dropoutRate = 0.5)\n",
        "\n",
        "l2_norm_clip = 1.5\n",
        "noise_multiplier = 0.5 # was 1.3\n",
        "batch_size = 16\n",
        "num_microbatches = 1\n",
        "learning_rate = 0.25\n",
        "batch_size = 16\n",
        "\n",
        "optimizer = DPGradientDescentGaussianOptimizer(\n",
        "    l2_norm_clip=1.0,      # Gradient clipping norm\n",
        "    noise_multiplier=0.5,  # Controls privacy strength (lower = more privacy)\n",
        "    num_microbatches=num_microbatches, # Use per-example gradients\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False, reduction=tf.losses.Reduction.NONE)\n",
        "\n",
        "\n",
        "\n",
        "# compile the model and set the optimizers\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "              metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# count number of parameters in the model\n",
        "numParams    = model.count_params()\n",
        "\n",
        "# set a valid path for your system to record model checkpoints\n",
        "checkpointer = ModelCheckpoint(filepath='./tmp/checkpoint.h5', verbose=1,\n",
        "                               save_best_only=True)\n",
        "\n",
        "###############################################################################\n",
        "# if the classification task was imbalanced (significantly more trials in one\n",
        "# class versus the others) you can assign a weight to each class during\n",
        "# optimization to balance it out. This data is approximately balanced so we\n",
        "# don't need to do this, but is shown here for illustration/completeness.\n",
        "###############################################################################\n",
        "\n",
        "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
        "# the weights all to be 1\n",
        "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
        "\n",
        "################################################################################\n",
        "# fit the model. Due to very small sample sizes this can get\n",
        "# pretty noisy run-to-run, but most runs should be comparable to xDAWN +\n",
        "# Riemannian geometry classification (below)\n",
        "################################################################################\n",
        "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300,\n",
        "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
        "                        callbacks=[checkpointer], class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "177c044b-9421-4dff-8458-eaf5c5f92eeb",
      "metadata": {
        "id": "177c044b-9421-4dff-8458-eaf5c5f92eeb"
      },
      "outputs": [],
      "source": [
        "# load optimal weights\n",
        "model.load_weights('./tmp/checkpoint.h5')\n",
        "\n",
        "###############################################################################\n",
        "# can alternatively used the weights provided in the repo. If so it should get\n",
        "# you 93% accuracy. Change the WEIGHTS_PATH variable to wherever it is on your\n",
        "# system.\n",
        "###############################################################################\n",
        "\n",
        "# WEIGHTS_PATH = /path/to/EEGNet-8-2-weights.h5\n",
        "# model.load_weights(WEIGHTS_PATH)\n",
        "\n",
        "###############################################################################\n",
        "# make prediction on test set.\n",
        "###############################################################################\n",
        "\n",
        "probs       = model.predict(X_test)\n",
        "preds       = probs.argmax(axis = -1)\n",
        "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
        "print(\"Classification accuracy: %f \" % (acc))\n",
        "\n",
        "\n",
        "############################# PyRiemann Portion ##############################\n",
        "\n",
        "# code is taken from PyRiemann's ERP sample script, which is decoding in\n",
        "# the tangent space with a logistic regression\n",
        "\n",
        "# n_components = 2  # pick some components\n",
        "\n",
        "# # set up sklearn pipeline\n",
        "# clf = make_pipeline(XdawnCovariances(n_components),\n",
        "#                     TangentSpace(metric='riemann'),\n",
        "#                     LogisticRegression())\n",
        "\n",
        "# preds_rg     = np.zeros(len(Y_test))\n",
        "\n",
        "# # reshape back to (trials, channels, samples)\n",
        "# X_train      = X_train.reshape(X_train.shape[0], chans, samples)\n",
        "# X_test       = X_test.reshape(X_test.shape[0], chans, samples)\n",
        "\n",
        "# # train a classifier with xDAWN spatial filtering + Riemannian Geometry (RG)\n",
        "# # labels need to be back in single-column format\n",
        "# clf.fit(X_train, Y_train.argmax(axis = -1))\n",
        "# preds_rg     = clf.predict(X_test)\n",
        "\n",
        "# # Printing the results\n",
        "# acc2         = np.mean(preds_rg == Y_test.argmax(axis = -1))\n",
        "# print(\"Classification accuracy: %f \" % (acc2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479529e4-0805-4614-9c11-d3307573550b",
      "metadata": {
        "id": "479529e4-0805-4614-9c11-d3307573550b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b1acb6-d7a5-4c3e-a425-20e001e60bfc",
      "metadata": {
        "id": "c9b1acb6-d7a5-4c3e-a425-20e001e60bfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da31ffd-76ad-4df9-9adb-ee085cb89abe",
      "metadata": {
        "id": "3da31ffd-76ad-4df9-9adb-ee085cb89abe"
      },
      "outputs": [],
      "source": [
        "# plot the confusion matrices for both classifiers\n",
        "names        = ['audio left', 'audio right', 'vis left', 'vis right']\n",
        "# plt.figure(0)\n",
        "confusion_matrix_1 = confusion_matrix(preds, Y_test.argmax(axis = -1))\n",
        "\n",
        "# plt.figure(1)\n",
        "# confusion_matrix_2 = confusion_matrix(preds_rg, Y_test.argmax(axis = -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "175bc807-af47-4dba-9d39-594fd9a468a9",
      "metadata": {
        "id": "175bc807-af47-4dba-9d39-594fd9a468a9"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9df05b-df60-45b6-a94a-7475449630c1",
      "metadata": {
        "id": "4f9df05b-df60-45b6-a94a-7475449630c1"
      },
      "outputs": [],
      "source": [
        "disp1 = ConfusionMatrixDisplay(confusion_matrix_1, display_labels = names)\n",
        "disp1.plot()\n",
        "\n",
        "# ConfusionMatrixDisplay(confusion_matrix_2, display_labels = names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a25f803-0a09-4be5-9a20-64902ee3637f",
      "metadata": {
        "id": "6a25f803-0a09-4be5-9a20-64902ee3637f"
      },
      "outputs": [],
      "source": [
        "print(classification_report(preds, Y_test.argmax(axis = -1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c882cd8a-cd00-422b-a63c-06d2b9cc3e15",
      "metadata": {
        "id": "c882cd8a-cd00-422b-a63c-06d2b9cc3e15"
      },
      "outputs": [],
      "source": [
        "#disp2 = ConfusionMatrixDisplay(confusion_matrix_2, display_labels = names)\n",
        "#disp2.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b5d049a-e8f5-4aa6-a4ce-9afe0015b82f",
      "metadata": {
        "id": "2b5d049a-e8f5-4aa6-a4ce-9afe0015b82f"
      },
      "outputs": [],
      "source": [
        "end = time.time()\n",
        "print(f\"Took {end - start:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IHjR6lgd5D_Y",
      "metadata": {
        "id": "IHjR6lgd5D_Y"
      },
      "outputs": [],
      "source": [
        "eps, _ = compute_dp_sgd_privacy_lib.compute_dp_sgd_privacy(n=X_train.shape[0],\n",
        "                      batch_size=batch_size,\n",
        "                      noise_multiplier=noise_multiplier,\n",
        "                      epochs=50,\n",
        "                      delta=1e-5)\n",
        "\n",
        "print(eps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "zazu2",
      "language": "python",
      "name": "zazu2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}